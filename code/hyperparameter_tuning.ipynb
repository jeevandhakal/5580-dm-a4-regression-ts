{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d484d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import time_operation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d2fc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîá Environment Silenced. GPU is ready for clean tuning.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- 1. SYSTEM & C++ LEVEL SILENCE ---\n",
    "# Directs NVIDIA compiler to be quiet and silences TF C++ logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_CPP_VMODULE'] = 'nvptx_compiler=0'\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_cpu_global_jit'\n",
    "\n",
    "# --- 2. PYTHON LEVEL SILENCE ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# This silences the \"All configs were filtered out\" XLA autotune spam\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "# --- 3. OPTUNA VERBOSITY ---\n",
    "# Set to INFO to see trial results, WARNING to see nothing but errors\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO) \n",
    "\n",
    "# --- 4. LIGHTGBM / XGBOOST INTERNAL SILENCE ---\n",
    "# Note: In your objective function, ensure you set:\n",
    "# lgb.LGBMRegressor(..., verbose=-1)\n",
    "# xgb.XGBRegressor(..., verbosity=0)\n",
    "\n",
    "print(\"üîá Environment Silenced. GPU is ready for clean tuning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb64a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Verify GPU is still active in this session\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7b2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for your 10-page report\n",
    "data_path = Path().cwd().parent / \"data\" / \"electricity_prediction.csv\"\n",
    "results_path = Path().cwd().parent / \"results\"\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569057e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully.\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 139571 entries, 0 to 139570\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Hour_1  139571 non-null  float64\n",
      " 1   Hour_2  139571 non-null  float64\n",
      " 2   Hour_3  139571 non-null  float64\n",
      " 3   Hour_4  139571 non-null  float64\n",
      " 4   Hour_5  139571 non-null  float64\n",
      " 5   Hour_6  139571 non-null  float64\n",
      " 6   Target  139571 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 7.5 MB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load data with header=None as the file lacks headers\n",
    "    df = pd.read_csv(data_path, header=None)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Data file not found. Please check the path.\")\n",
    "else:\n",
    "    # Rename columns\n",
    "    column_names = [f'Hour_{i}' for i in range(1, 7)] + ['Target']\n",
    "    df.columns = column_names\n",
    "    print(\"Data Loaded Successfully.\")\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10cc0f",
   "metadata": {},
   "source": [
    "## --- STEP 1: LOAD & DECORATED PREPROCESSING ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b5f2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared in 52.12 ms. Shape: (139403, 12)\n"
     ]
    }
   ],
   "source": [
    "@time_operation\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Combines feature engineering and scaling.\n",
    "    Recorded time will include the generation of 13 features.\n",
    "    \"\"\"\n",
    "    X = df.copy()\n",
    "    series = X['Target']\n",
    "    \n",
    "    # 1. Cyclical Features\n",
    "    hour_series = X.index % 24\n",
    "    X['Hour_Sin'] = np.sin(2 * np.pi * hour_series / 24)\n",
    "    X['Hour_Cos'] = np.cos(2 * np.pi * hour_series / 24)\n",
    "    \n",
    "    # 2. Lags & Rolling Stats\n",
    "    X['Lag_24'] = series.shift(24)\n",
    "    X['Lag_168'] = series.shift(168)\n",
    "    X['Rolling_Mean_6'] = series.shift(1).rolling(window=6).mean()\n",
    "    X['Rolling_Std_24'] = series.shift(1).rolling(window=24).std()\n",
    "    \n",
    "    # 3. Clean and Split\n",
    "    X = X.dropna()\n",
    "    y = X['Target']\n",
    "    X = X.drop(columns=['Target'])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Execute and record time\n",
    "(X_eng, y_eng), prep_time = prepare_data(df)\n",
    "print(f\"Data prepared in {prep_time:.2f} ms. Shape: {X_eng.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4091c4d",
   "metadata": {},
   "source": [
    "## Step 2: The Chronological Split\n",
    "First, we must partition the data. Since your ACF plot showed high temporal dependency, we keep the sequences intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a85f5b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete. Training on 97582 samples.\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 2: CHRONOLOGICAL SPLIT ---\n",
    "\n",
    "# 70% Train, 15% Val, 15% Test\n",
    "train_size = int(len(X_eng) * 0.70)\n",
    "val_size = int(len(X_eng) * 0.15)\n",
    "\n",
    "X_train, y_train = X_eng.iloc[:train_size], y_eng.iloc[:train_size]\n",
    "X_val, y_val = X_eng.iloc[train_size:train_size+val_size], y_eng.iloc[train_size:train_size+val_size]\n",
    "X_test, y_test = X_eng.iloc[train_size+val_size:], y_eng.iloc[train_size+val_size:]\n",
    "\n",
    "# Scaling - Critical for SVR, NN, and Linear Regression\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler() # Scaling target helps Neural Networks converge faster\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Reshape y for the scaler\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"Split complete. Training on {len(X_train)} samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a6be47",
   "metadata": {},
   "source": [
    "## save the sets train/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "834a7330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data bundle saved to: /home/bhavik/Dropbox/edu/smu/winter/data_mining/a4_regression_ts/data/electricity_data_split.pkl\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# 1. Setup the data directory\n",
    "data_path = Path().cwd().parent / \"data\"\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Package all sets (including the unscaled ones for reference)\n",
    "data_bundle = {\n",
    "    \"X_train_scaled\": X_train_scaled,\n",
    "    \"X_val_scaled\": X_val_scaled,\n",
    "    \"X_test_scaled\": X_test_scaled,\n",
    "    \"y_train_scaled\": y_train_scaled,\n",
    "    \"y_val_scaled\": y_val_scaled,\n",
    "    \"y_test_scaled\": y_test_scaled\n",
    "}\n",
    "\n",
    "# 3. Save to the data folder\n",
    "joblib.dump(data_bundle, data_path / \"electricity_data_split.pkl\")\n",
    "print(f\"‚úÖ Data bundle saved to: {data_path / 'electricity_data_split.pkl'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a18be",
   "metadata": {},
   "source": [
    "## Step 3: Performance & Time Tracking Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0254f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "results_registry = {}\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, model_name, duration_ms):\n",
    "    \"\"\"\n",
    "    Calculates MAPE, RMSE, and MAE. \n",
    "    Stores results in the global registry for the 10-page report.\n",
    "    \"\"\"\n",
    "    # MAPE calculation\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    # RMSE calculation (requires sklearn.metrics.mean_squared_error)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    # MAE calculation (requires sklearn.metrics.mean_absolute_error)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # Store in registry\n",
    "    results_registry[model_name] = {\n",
    "        \"MAPE\": mape,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"Time_ms\": duration_ms\n",
    "    }\n",
    "    \n",
    "    print(f\"--- {model_name} Results ---\")\n",
    "    print(f\"MAPE: {mape:.2f}% | RMSE: {rmse:.2f} | Time: {duration_ms:.2f} ms\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6869c935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:19:49,405]\u001b[0m A new study created in memory with name: Electricity_Consumption_Tuning\u001b[0m\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1770585589.575484   36665 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6223 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2026-02-08 17:19:52.818119: I external/local_xla/xla/service/service.cc:163] XLA service 0x774f68004c60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-02-08 17:19:52.818173: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2026-02-08 17:19:52.896217: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-02-08 17:19:53.373539: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91900\n",
      "2026-02-08 17:19:53.449664: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:19:53.449796: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:19:53.449886: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:19:54.451250: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_164', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:54.966755: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 292 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:55.099742: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:55.134346: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 304 bytes spill stores, 304 bytes spill loads\n",
      "\n",
      "I0000 00:00:1770585596.862363   37025 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2026-02-08 17:19:57.735335: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:19:57.735370: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:19:57.735383: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:19:57.735425: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:19:58.190335: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_164', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:58.359747: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 292 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:58.636080: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:58.976478: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_358', 576 bytes spill stores, 576 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:59.132097: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_164', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:59.418248: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_164', 216 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:59.618230: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:59.863042: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:59.891446: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_358', 120 bytes spill stores, 124 bytes spill loads\n",
      "\n",
      "2026-02-08 17:19:59.904081: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 308 bytes spill stores, 308 bytes spill loads\n",
      "\n",
      "2026-02-08 17:20:00.009095: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_358', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "2026-02-08 17:20:00.057126: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 392 bytes spill stores, 392 bytes spill loads\n",
      "\n",
      "2026-02-08 17:20:22.388214: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:20:28,128]\u001b[0m Trial 0 finished with value: 1.1823490650630526 and parameters: {'model_type': 'NN_3_Layer', 'u0_NN_3_Layer': 204, 'u1_NN_3_Layer': 61, 'u2_NN_3_Layer': 114}. Best is trial 0 with value: 1.1823490650630526.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:20:38,239]\u001b[0m Trial 1 finished with value: 1.1700158843582469 and parameters: {'model_type': 'LightGBM'}. Best is trial 1 with value: 1.1700158843582469.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:20:47,180]\u001b[0m Trial 2 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:20:56,303]\u001b[0m Trial 3 finished with value: 1.2254853762029063 and parameters: {'model_type': 'SVR', 'svr_kernel': 'rbf', 'SVR_C': 8.571718610202538}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "2026-02-08 17:20:58.413259: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_150', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:20:59.812620: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_356', 10168 bytes spill stores, 10180 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:02.019651: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:02.019683: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:02.019706: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:02.462992: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:02.850328: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:03.163574: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 604 bytes spill stores, 452 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:03.245029: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:03.398119: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 272 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:03.413030: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_164', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:03.976759: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:26.367523: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:26.367599: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:26.970256: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:27.343246: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 284 bytes spill stores, 284 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:27.599618: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:27.625298: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 296 bytes spill stores, 296 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:21:31,867]\u001b[0m Trial 4 finished with value: 1.1999721796113332 and parameters: {'model_type': 'NN_3_Layer', 'u0_NN_3_Layer': 195, 'u1_NN_3_Layer': 129, 'u2_NN_3_Layer': 122}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "2026-02-08 17:21:33.368692: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:33.368746: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:37.193597: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:37.193626: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:37.193640: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:37.792954: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_157', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:37.878243: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:52.815590: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:21:53.248640: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:53.277681: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2026-02-08 17:21:53.519746: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:21:57,425]\u001b[0m Trial 5 finished with value: 1.1710368987361477 and parameters: {'model_type': 'NN_3_Layer', 'u0_NN_3_Layer': 194, 'u1_NN_3_Layer': 76, 'u2_NN_3_Layer': 128}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:22:27,046]\u001b[0m Trial 6 finished with value: 1.1954904308134586 and parameters: {'model_type': 'SVR', 'svr_kernel': 'linear', 'SVR_C': 6.900028377110187}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:22:28,047]\u001b[0m Trial 7 finished with value: 1.2014676505974566 and parameters: {'model_type': 'XGBoost'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:22:28,071]\u001b[0m Trial 8 finished with value: 1.2805548816082095 and parameters: {'model_type': 'LinearRegression'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:22:28,096]\u001b[0m Trial 9 finished with value: 1.2805548816082095 and parameters: {'model_type': 'LinearRegression'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:22:37,785]\u001b[0m Trial 10 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:22:47,057]\u001b[0m Trial 11 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:22:55,971]\u001b[0m Trial 12 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:22:57,667]\u001b[0m Trial 13 finished with value: 10.605591287794773 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 1, 'q': 1}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "2026-02-08 17:22:59.371290: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_82', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:23:25,594]\u001b[0m Trial 14 finished with value: 1.1975900662220684 and parameters: {'model_type': 'NN_1_Layer', 'u0_NN_1_Layer': 163}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:23:25,900]\u001b[0m Trial 15 finished with value: 1.526196010440881 and parameters: {'model_type': 'RegressionTree', 'dt_depth': 4}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:23:58,710]\u001b[0m Trial 16 finished with value: 14.754727048241548 and parameters: {'model_type': 'HoltWinters'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:25:50,437]\u001b[0m Trial 17 finished with value: 4.415340467882024 and parameters: {'model_type': 'ARIMA', 'p': 3, 'd': 0, 'q': 3}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:26:03,662]\u001b[0m Trial 18 finished with value: 1.002423087364464 and parameters: {'model_type': 'ARIMA', 'p': 1, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:26:04,645]\u001b[0m Trial 19 finished with value: 1.5644294631276563 and parameters: {'model_type': 'RegressionTree', 'dt_depth': 20}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:26:13,995]\u001b[0m Trial 20 finished with value: 1.1700138787889627 and parameters: {'model_type': 'LightGBM'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:26:23,306]\u001b[0m Trial 21 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:26:37,754]\u001b[0m Trial 22 finished with value: 1.010558474206348 and parameters: {'model_type': 'ARIMA', 'p': 1, 'd': 0, 'q': 1}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:26:40,351]\u001b[0m Trial 23 finished with value: 10.56001027788539 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 1, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:26:41,148]\u001b[0m Trial 24 finished with value: 1.2014676505974566 and parameters: {'model_type': 'XGBoost'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:27:35,795]\u001b[0m Trial 25 finished with value: 14.754727048241548 and parameters: {'model_type': 'HoltWinters'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "2026-02-08 17:27:37.612618: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_248', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2026-02-08 17:27:40.295480: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_248', 620 bytes spill stores, 620 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:28:02,223]\u001b[0m Trial 26 finished with value: 1.2478644982852893 and parameters: {'model_type': 'NN_1_Layer', 'u0_NN_1_Layer': 37}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:28:16,545]\u001b[0m Trial 27 finished with value: 1.010558474206348 and parameters: {'model_type': 'ARIMA', 'p': 1, 'd': 0, 'q': 1}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:28:25,739]\u001b[0m Trial 28 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:29:40,195]\u001b[0m Trial 29 finished with value: 1.0153069377415398 and parameters: {'model_type': 'ARIMA', 'p': 3, 'd': 0, 'q': 2}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:29:44,913]\u001b[0m Trial 30 finished with value: 10.677154054789584 and parameters: {'model_type': 'ARIMA', 'p': 2, 'd': 1, 'q': 1}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:29:54,755]\u001b[0m Trial 31 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:30:05,143]\u001b[0m Trial 32 finished with value: 1.170271293755341 and parameters: {'model_type': 'LightGBM'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:30:14,646]\u001b[0m Trial 33 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:30:21,196]\u001b[0m Trial 34 finished with value: 1.1762482066984417 and parameters: {'model_type': 'SVR', 'svr_kernel': 'rbf', 'SVR_C': 0.6839107352478422}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "2026-02-08 17:30:23.027919: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:30:23.519040: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:23.710614: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_157', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:23.914392: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:24.268509: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_157', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:24.842062: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_354', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:25.825869: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_358', 13684 bytes spill stores, 14584 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:29.278915: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:30:30.382838: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_157', 156 bytes spill stores, 156 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:30.686633: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_157', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:31.045948: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_354', 620 bytes spill stores, 620 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:53.692672: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:30:54.223186: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:30:54.430475: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:30:59,117]\u001b[0m Trial 35 finished with value: 1.1784105768039124 and parameters: {'model_type': 'NN_3_Layer', 'u0_NN_3_Layer': 35, 'u1_NN_3_Layer': 248, 'u2_NN_3_Layer': 212}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:31:08,152]\u001b[0m Trial 36 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:31:08,960]\u001b[0m Trial 37 finished with value: 1.2014676505974566 and parameters: {'model_type': 'XGBoost'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:31:09,029]\u001b[0m Trial 38 finished with value: 1.2805548816082095 and parameters: {'model_type': 'LinearRegression'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:31:22,637]\u001b[0m Trial 39 finished with value: 1.1961911616524128 and parameters: {'model_type': 'SVR', 'svr_kernel': 'linear', 'SVR_C': 2.0825899646584003}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "2026-02-08 17:31:25.282942: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:31:25.283016: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:31:26.236010: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2026-02-08 17:31:26.434182: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 292 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "2026-02-08 17:31:26.777062: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "2026-02-08 17:31:27.421437: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 380 bytes spill stores, 288 bytes spill loads\n",
      "\n",
      "2026-02-08 17:31:29.617364: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:31:29.617415: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:31:30.874495: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 292 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "2026-02-08 17:31:30.926785: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 612 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "2026-02-08 17:31:30.934678: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 392 bytes spill stores, 392 bytes spill loads\n",
      "\n",
      "2026-02-08 17:31:51.735446: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:31:51.735524: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:31:52.484562: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-02-08 17:31:52.709442: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2026-02-08 17:31:52.744515: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:31:58,526]\u001b[0m Trial 40 finished with value: 1.207315166513519 and parameters: {'model_type': 'NN_3_Layer', 'u0_NN_3_Layer': 78, 'u1_NN_3_Layer': 248, 'u2_NN_3_Layer': 33}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:32:07,872]\u001b[0m Trial 41 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:32:16,971]\u001b[0m Trial 42 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:32:29,602]\u001b[0m Trial 43 finished with value: 1.002423087364464 and parameters: {'model_type': 'ARIMA', 'p': 1, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:32:54,406]\u001b[0m Trial 44 finished with value: 1.2469750774612243 and parameters: {'model_type': 'NN_1_Layer', 'u0_NN_1_Layer': 246}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:32:54,943]\u001b[0m Trial 45 finished with value: 1.290845637835094 and parameters: {'model_type': 'RegressionTree', 'dt_depth': 14}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:33:38,574]\u001b[0m Trial 46 finished with value: 14.754727048241548 and parameters: {'model_type': 'HoltWinters'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:33:48,348]\u001b[0m Trial 47 finished with value: 0.9999905973940331 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 0}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:33:48,363]\u001b[0m Trial 48 finished with value: 1.2805548816082095 and parameters: {'model_type': 'LinearRegression'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:33:56,845]\u001b[0m Trial 49 finished with value: 1.1702757146536253 and parameters: {'model_type': 'LightGBM'}. Best is trial 2 with value: 0.9999905973940331.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:34:06,095]\u001b[0m Trial 50 finished with value: 0.9999725185918287 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 1}. Best is trial 50 with value: 0.9999725185918287.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:34:15,290]\u001b[0m Trial 51 finished with value: 0.9999725185918287 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 1}. Best is trial 50 with value: 0.9999725185918287.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:34:24,264]\u001b[0m Trial 52 finished with value: 0.9999725185918287 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 1}. Best is trial 50 with value: 0.9999725185918287.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:34:33,496]\u001b[0m Trial 53 finished with value: 0.9999725185918287 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 1}. Best is trial 50 with value: 0.9999725185918287.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:34:42,136]\u001b[0m Trial 54 finished with value: 0.9999725185918287 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 1}. Best is trial 50 with value: 0.9999725185918287.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:34:55,808]\u001b[0m Trial 55 finished with value: 1.010558474206348 and parameters: {'model_type': 'ARIMA', 'p': 1, 'd': 0, 'q': 1}. Best is trial 50 with value: 0.9999725185918287.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:35:10,518]\u001b[0m Trial 56 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:35:25,756]\u001b[0m Trial 57 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:35:39,597]\u001b[0m Trial 58 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:35:40,336]\u001b[0m Trial 59 finished with value: 1.2014676505974566 and parameters: {'model_type': 'XGBoost'}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:35:40,534]\u001b[0m Trial 60 finished with value: 1.3445124007556823 and parameters: {'model_type': 'RegressionTree', 'dt_depth': 3}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:35:56,012]\u001b[0m Trial 61 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:36:10,160]\u001b[0m Trial 62 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:36:24,860]\u001b[0m Trial 63 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:36:39,338]\u001b[0m Trial 64 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:36:53,987]\u001b[0m Trial 65 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "2026-02-08 17:36:55.610780: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_248', 328 bytes spill stores, 328 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:37:21,885]\u001b[0m Trial 66 finished with value: 1.1888768763227173 and parameters: {'model_type': 'NN_1_Layer', 'u0_NN_1_Layer': 64}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:37:59,365]\u001b[0m Trial 67 finished with value: 14.754727048241548 and parameters: {'model_type': 'HoltWinters'}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:38:14,147]\u001b[0m Trial 68 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:38:22,203]\u001b[0m Trial 69 finished with value: 1.238630578454687 and parameters: {'model_type': 'SVR', 'svr_kernel': 'rbf', 'SVR_C': 4.245903258404162}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "2026-02-08 17:38:25.076896: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_150', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:27.511789: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_358', 10168 bytes spill stores, 10180 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:29.373317: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:38:29.373453: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:38:30.354997: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:30.607038: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 272 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:31.049615: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 604 bytes spill stores, 452 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:31.095398: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_157', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:31.625096: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_157', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:53.935776: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:38:53.935924: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:38:55.048701: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 632 bytes spill stores, 628 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:55.159376: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 616 bytes spill stores, 608 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:55.252102: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 280 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "2026-02-08 17:38:55.861558: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 280 bytes spill stores, 280 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:38:59,222]\u001b[0m Trial 70 finished with value: 1.1623891249673788 and parameters: {'model_type': 'NN_3_Layer', 'u0_NN_3_Layer': 117, 'u1_NN_3_Layer': 173, 'u2_NN_3_Layer': 247}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:39:13,683]\u001b[0m Trial 71 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:39:28,653]\u001b[0m Trial 72 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:39:43,607]\u001b[0m Trial 73 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:39:58,202]\u001b[0m Trial 74 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:40:13,588]\u001b[0m Trial 75 finished with value: 0.9999401814718625 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 2}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:40:23,044]\u001b[0m Trial 76 finished with value: 1.1702681472766054 and parameters: {'model_type': 'LightGBM'}. Best is trial 56 with value: 0.9999401814718625.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:40:41,406]\u001b[0m Trial 77 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:41:00,778]\u001b[0m Trial 78 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:41:00,794]\u001b[0m Trial 79 finished with value: 1.2805548816082095 and parameters: {'model_type': 'LinearRegression'}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:42:12,704]\u001b[0m Trial 80 finished with value: 1.0134890486766643 and parameters: {'model_type': 'ARIMA', 'p': 2, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:42:32,070]\u001b[0m Trial 81 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:42:52,205]\u001b[0m Trial 82 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:43:11,205]\u001b[0m Trial 83 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:43:30,209]\u001b[0m Trial 84 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:43:31,090]\u001b[0m Trial 85 finished with value: 1.2014676505974566 and parameters: {'model_type': 'XGBoost'}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:43:49,966]\u001b[0m Trial 86 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:44:21,974]\u001b[0m Trial 87 finished with value: 1.0115012882255632 and parameters: {'model_type': 'ARIMA', 'p': 1, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:44:46,809]\u001b[0m Trial 88 finished with value: 1.1953035242031689 and parameters: {'model_type': 'SVR', 'svr_kernel': 'linear', 'SVR_C': 4.754785104817089}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:44:47,817]\u001b[0m Trial 89 finished with value: 1.2592952098768573 and parameters: {'model_type': 'RegressionTree', 'dt_depth': 11}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:44:51,820]\u001b[0m Trial 90 finished with value: 10.656968585920861 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 1, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:45:10,320]\u001b[0m Trial 91 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:45:28,826]\u001b[0m Trial 92 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:45:48,652]\u001b[0m Trial 93 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "2026-02-08 17:45:49.793007: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_82', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:46:15,627]\u001b[0m Trial 94 finished with value: 1.1814655170080242 and parameters: {'model_type': 'NN_1_Layer', 'u0_NN_1_Layer': 251}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:46:33,908]\u001b[0m Trial 95 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "2026-02-08 17:46:35.543427: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:46:35.543456: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:46:35.908072: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_150', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:36.081456: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:36.414606: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:36.450384: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:37.800927: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_356', 13064 bytes spill stores, 14236 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:40.702283: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:46:40.702356: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:46:40.702751: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:46:41.173315: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_164', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:41.458572: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_342', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:41.813302: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_358', 108 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:41.972222: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_358', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:42.230921: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_358', 164 bytes spill stores, 164 bytes spill loads\n",
      "\n",
      "2026-02-08 17:46:42.392573: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_330', 332 bytes spill stores, 332 bytes spill loads\n",
      "\n",
      "2026-02-08 17:47:05.601894: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:47:05.602007: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2026-02-08 17:47:06.598297: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 644 bytes spill stores, 564 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-08 17:47:11,027]\u001b[0m Trial 96 finished with value: 1.196926866961114 and parameters: {'model_type': 'NN_3_Layer', 'u0_NN_3_Layer': 249, 'u1_NN_3_Layer': 172, 'u2_NN_3_Layer': 40}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:47:28,951]\u001b[0m Trial 97 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:48:10,444]\u001b[0m Trial 98 finished with value: 14.754727048241548 and parameters: {'model_type': 'HoltWinters'}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n",
      "\u001b[32m[I 2026-02-08 17:48:29,558]\u001b[0m Trial 99 finished with value: 0.999921814554208 and parameters: {'model_type': 'ARIMA', 'p': 0, 'd': 0, 'q': 3}. Best is trial 77 with value: 0.999921814554208.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # 1. SELECT THE ARCHITECTURE\n",
    "    model_type = trial.suggest_categorical('model_type', [\n",
    "        'LinearRegression', 'HoltWinters', 'ARIMA', 'SVR', \n",
    "        'RegressionTree', 'XGBoost', 'LightGBM', \n",
    "        'NN_1_Layer', 'NN_3_Layer'\n",
    "    ])\n",
    "    \n",
    "    # --- MODEL IMPLEMENTATIONS ---\n",
    "    if model_type == 'LinearRegression':\n",
    "        model = LinearRegression().fit(X_train_scaled, y_train_scaled)\n",
    "        preds = model.predict(X_val_scaled)\n",
    "\n",
    "    elif model_type == 'HoltWinters':\n",
    "        model = ExponentialSmoothing(y_train_scaled, trend='add', seasonal='add', seasonal_periods=24).fit()\n",
    "        preds = model.forecast(len(y_val_scaled))\n",
    "\n",
    "    elif model_type == 'ARIMA':\n",
    "        p, d, q = trial.suggest_int('p', 0, 3), trial.suggest_int('d', 0, 1), trial.suggest_int('q', 0, 3)\n",
    "        try:\n",
    "            model = ARIMA(y_train_scaled, order=(p, d, q)).fit()\n",
    "            preds = model.forecast(steps=len(y_val_scaled))\n",
    "        except: return 1.0 # High error for non-convergent trials\n",
    "\n",
    "    elif model_type == 'SVR':\n",
    "        kernel = trial.suggest_categorical('svr_kernel', ['linear', 'rbf'])\n",
    "        idx = np.random.choice(len(X_train_scaled), int(len(X_train_scaled)*0.1), replace=False)\n",
    "        model = SVR(kernel=kernel, C=trial.suggest_float('SVR_C', 0.1, 10.0)).fit(X_train_scaled[idx], y_train_scaled[idx])\n",
    "        preds = model.predict(X_val_scaled)\n",
    "\n",
    "    elif model_type == 'RegressionTree':\n",
    "        model = DecisionTreeRegressor(max_depth=trial.suggest_int('dt_depth', 3, 20)).fit(X_train_scaled, y_train_scaled)\n",
    "        preds = model.predict(X_val_scaled)\n",
    "\n",
    "    elif model_type == 'XGBoost':\n",
    "        model = xgb.XGBRegressor(tree_method='hist', device='cuda', n_estimators=500).fit(X_train_scaled, y_train_scaled)\n",
    "        preds = model.predict(X_val_scaled)\n",
    "\n",
    "    elif model_type == 'LightGBM':\n",
    "        model = lgb.LGBMRegressor(device='gpu', n_estimators=500, verbose=-1).fit(X_train_scaled, y_train_scaled)\n",
    "        preds = model.predict(X_val_scaled)\n",
    "\n",
    "    elif 'NN' in model_type:\n",
    "        num_layers = 1 if '1_Layer' in model_type else 3\n",
    "        model = tf.keras.Sequential([tf.keras.layers.Input(shape=(X_train_scaled.shape[1],))])\n",
    "        for i in range(num_layers):\n",
    "            units = trial.suggest_int(f'u{i}_{model_type}', 32, 256)\n",
    "            model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X_train_scaled, y_train_scaled, epochs=30, batch_size=1024, verbose=0)\n",
    "        preds = model.predict(X_val_scaled).flatten()\n",
    "\n",
    "    return mean_absolute_percentage_error(y_val_scaled, preds)\n",
    "\n",
    "# --- EXECUTE THE NAMED STUDY ---\n",
    "study_name = \"Electricity_Consumption_Tuning\"\n",
    "study = optuna.create_study(study_name=study_name, direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c93d9555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 100 trials saved to /home/bhavik/Dropbox/edu/smu/winter/data_mining/a4_regression_ts/results/optuna_trials_final.csv\n",
      "üì¶ Study object serialized to /home/bhavik/Dropbox/edu/smu/winter/data_mining/a4_regression_ts/results/electricity_study.pkl\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# 1. Define and Create Results Folder\n",
    "# Using Path objects makes directory creation more robust\n",
    "# 2. Export human-readable results (MAPE, parameters, etc.)\n",
    "# Optuna dataframes can be saved directly using path objects\n",
    "df_trials = study.trials_dataframe()\n",
    "csv_file = results_path / \"optuna_trials_final.csv\"\n",
    "df_trials.to_csv(csv_file, index=False)\n",
    "\n",
    "# 3. Save the actual Optuna Study Object\n",
    "# This is your \"insurance policy\" for the 10-page report\n",
    "pickle_file = results_path / \"electricity_study.pkl\"\n",
    "joblib.dump(study, pickle_file)\n",
    "\n",
    "print(f\"‚úÖ 100 trials saved to {csv_file}\")\n",
    "print(f\"üì¶ Study object serialized to {pickle_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
